<br>
<br>

Logic, First Course, Winter 2020. Week 9, Lecture 1, Handout.

# Pragmatics and conversational implicature



*Example 1.*

<p style="margin-left: 40px"> $w$ = Cameron returned from $w$ork </p>
<p style="margin-left: 40px"> $s$ = Cameron fell a$s$leep </p>

~~~{.Translate .Prop system="gamutPND" submission="none"}
 w/\s : Cameron returned from work and he fell asleep.
~~~

~~~{.Translate .Prop system="gamutPND" submission="none"}
 s/\w : Cameron fell asleep and he returned from work.
~~~

But we know that the following holds, as well as the converse direction:

```{.ProofChecker .GamutPNDPlus submission="none"}
 w/\s :|-: s/\w
|w/\s :assumption
```
Intuitively there is no entailment between the first sentence and the second sentence. For the situations in which Cameron first returns from work and then falls asleep seem to be different from the situations in which he does it the other way around.

<br>

*Example 2*.

Consider the following three exchanges between Laura and Sofia:

<p style="margin-left: 40px"> Laura: Where is the coffee shop? </p>
<p style="margin-left: 40px"> Sofia: on 6th st. or 7th street. </p>

<br>

<p style="margin-left: 40px"> Laura: When is the exam? </p>
<p style="margin-left: 40px"> Sofia: On Monday or Tuesday. </p>

<br>

<p style="margin-left: 40px"> Laura: Where is Cameron? </p>
<p style="margin-left: 40px"> Sofia: at school or at the coffee shop. </p>

So Laura asks Sofia a question and Sofia responds with $\phi\vee \psi$. An intuitive thought is that Laura should be able to infer that Sofia does not know $\phi$ and that Sofia does not know $\psi$. What could possibly account for the intuitive thought besides the meaning of "or"? After all, thatâ€™s the only thing that is common to all Sofia's answers.


<br>

*Example 3*.

In this, we use the following key:

| $a$  =  "Angel"
| $b$  =  "Briana"
| $c$  =  "Cole"
| $F$  =  "is a French major"
| $H$  = "is happy"
| $T$  =  "is tall"

<br>

~~~{.Translate .FOL system="gamutND" submission="none"}
 Ax((Tx/\Fx)->Hx) : All tall French majors are happy.
~~~

~~~{.Translate .FOL system="gamutND" submission="none"}
 Ex(Fx/\Tx) : Some French majors are tall.
~~~

Intuitively, it seems that someone who asserts "All tall French majors are happy" also would intend "Some French majors are tall." However, if this entailment is guaranteed by validity, we should be able to assess it.

The first step is to translate it into something more like propositional logic. Suppose that there are only three people at our very small campus, say Angel, Briana, and Cole.

~~~{.Translate .FOL system="gamutND" submission="none"}
 ((Ta/\Fa)->Ha)/\(((Tb/\Fb)->Hb)/\((Tb/\Fb)->Hb)) : Find an equivalent of "All tall French majors are happy" in predicate logic without using a quantifier, under the hypothesis that there are only three people a,b,c.
~~~

~~~{.Translate .FOL system="gamutND" submission="none"}
 (Fa/\Ta)\/((Fb/\Tb)\/(Fc/\Tc)) : Find an equivalent of "Some French majors are tall" in predicate logic without using a quantifier, under the hypothesis that there are only three people a,b,c.
~~~

By using the following further key, we can translate into pure propositional logic:

| i  =  $Ta$
| j  =  $Fa$
| k  =  $Ha$
| m  =  $Tb$
| n  =  $Fb$
| o  =  $Hb$
| p  =  $Tc$
| q  =  $Fc$
| r  =  $Hc$

We would then ask whether the following is valid:

<p style="margin-left: 40px"> $((i\wedge j)\rightarrow k)\wedge(((m\wedge n)\rightarrow o)\wedge((p\wedge q)\rightarrow r))\vdash (j\wedge i)\vee ((n\wedge m)\vee (q\wedge p))$ </p>


The invalidity of this complex argument would then be conceptually proximate to the invalidity of this simpler argument:

```{.TruthTable .Validity system="gamutPND" submission="none" options="nodash autoAtoms"}
 ((i/\j)->k) :|-: (j/\i)
```

Thus, "All tall French majors are happy" does *not* have as a consequence "Some French majors are tall," indicating again a divergence between the formal notion of consequence and the more intuitive notion of consequence.

<br>
<br>

## Conversational implicature


*Example 4*.

<p style="margin-left: 40px"> Laura: I need to print my homework. </p>
<p style="margin-left: 40px"> Sofia: There is a computer lab in the library. </p>

It seems natural that Laura should infer that Sofia thinks that there are printers in the computer lab in the library. But this inference does not follow from logic-- indeed, nowadays there are lots of computers without printers. If it does not follow from logic, what does it follow from? Grice's idea was that it followed from logic plus rules governing conversations.

The most basic rule governing conversations that Grice articulated was the following *cooperative principle*:

<img src="http://logic-teaching.github.io/prop/texts/Grice%201975%20-%20Logic%20and%20Conversation%20p.%2045%20v1.png" alt="quotation from Grice" width="700"/>

<img src="http://logic-teaching.github.io/prop/texts/Grice%201975%20-%20Logic%20and%20Conversation%20p.%2045%20v2.png" alt="quotation from Grice" width="700"/>

He further broke this down into several more specific maxims:


*Quantity*:

1. Make your contribution to the conversation as informative as is required (for the current purposes of the exchange).
2. Do not make your contribution more informative than is required.

*Quality*:

1. Do not say that which you believe to be false.
2. Do not say that for which you lack adequate evidence.

*Relation*:

1. Be relevant.

*Manner*:

1. Avoid obscurity of expression.
2. Avoid ambiguity.
3. Be brief.
4. Be orderly.


We can then define the key notion of conversational implicature as follows. Suppose that two people $S$ and $L$ are talking with another, where $S$ stands for the *speaker*, and $L$ stands for the *listener.* Suppose that $S$ says $p$. Then $q$ is a **conversational implicature** of $S$'s saying $p$ if:

- Prior to saying this, $S$ has not violated Grice's maxims.
- If $\neg q$, then $S$ violates Grice's maxims by saying $p$.
- Both $S$ and $L$ know these first two points.


To illustrate, let us return to the example of the printer and the computer lab in the library:

<p style="margin-left: 40px"> Laura: I need to print my homework. </p>
<p style="margin-left: 40px"> Sofia: There is a computer lab in the library. </p>

Obviously Laura should infer from Sofia's having said $p=$ "There is a computer lab in the library" that $q=$ Sofia believes that there is a printer in the computer lab in the library. Let's check to see that this is indeed a conversational implicature of Sofia's having said $p$. For, if $\neg q$, then Sofia did not believe that there is a printer in the computer lab in the library. Then it seems like Sofia is violating Grice's maxim of relation which says that one's contribution to the conversation must be relevant.

<br>
<br>

## Revisiting divergences

Let us now revisit Examples 1-3 and apply conversational implicature to these contexts.

<br>

*Revisiting Example 1*.

Suppose that Sofia said that $p$ = "Cameron returned from work and he fell asleep." Consider $q=$ Sofia believes that Cameron returned from work and then he fell asleep. Then we claim that $q$ is a conversational implicature of $S$'s having said $p$.

<br>

*Revisiting Example 2*.

In this example, Laura asks Sofia a question and Sofia responds by saying $p=(\phi\vee \psi)$. The intuitive thought is that Laura should be able to infer that $q$= Sofia does not know $\phi$ (and by parity of reasoning that Sofia does not know $\psi$). Let us show that $q$ is a conversational implicature of Sofia's having said $p$.

<br>

*Revisiting Example 3*.

In this example, the speaker $S$ says $p$= "All tall French majors are happy." Consider $q=$ the speaker $S$ believes that "Some French majors are tall." Let's argue that $q$ is a conversational implicature of $S$'s having said $p$. For, suppose $\neg q$. Then $S$ does not believe that some French majors are tall. But then trivially "All tall French majors are happy." This is a trivial consequence, for the same reason that the following is trivial:

<p style="margin-left: 40px"> $\neg ((j\wedge i)\vee ((n\wedge m)\vee (q\wedge p))) \vdash ((i\wedge j)\rightarrow k)\wedge(((m\wedge n)\rightarrow o)\wedge((p\wedge q)\rightarrow r))$ </p>

The triviality here pertains to the fact that the $k, o, r$ could be anything. The proof is not difficult, given the proof system we learned last week:


```{.ProofChecker .GamutPNDPlus submission="none"}
 ~((j/\i)\/((n/\m)\/(q/\p)))  :|-: ((i/\j)->k)/\(((m/\n)->o)/\((p/\q)->r))
|~((j/\i)\/((n/\m)\/(q/\p))) :assumption
```


<br>
<br>
<br>
<br>


This is a handout written for this [this course](https://ccle.ucla.edu/course/view.php?id=82647&section=9).[^2]


[^2]:It is run on the Carnap software, which is
